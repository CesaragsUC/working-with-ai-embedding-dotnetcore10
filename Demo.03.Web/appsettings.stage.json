{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning",
      "Microsoft.EntityFrameworkCore.Database.Command": "None",
      "Microsoft.EntityFrameworkCore": "Warning"
    }
  },
  "Serilog": {
    "Using": [ "Serilog.Sinks.Console", "Serilog.Sinks.Seq" ],
    "MinimumLevel": {
      "Default": "Information",
      "Override": {
        "Microsoft": "Warning",
        "System": "Warning"
      }
    },
    "Enrich": [ "FromLogContext", "WithMachineName" ],
    "WriteTo": [
      {
        "Name": "Console"
      },
      {
        "Name": "Seq",
        "Args": {
          "serverUrl": "http://localhost:5341"
        }
      }
    ]
  },
  "ConnectionStrings": {
    "DefaultConnection": "Host=localhost;Port=5432;Database=example_db;Username=postgres;Password=postgres"
  },
  "GeminiAI": {
    "ChatModel": "gemini-2.5-flash",
    "ImageModel": "",
    "AudioModel": "",
    "VideoModel": "",
    "EmbeddingGeneratorModel": "text-embedding-004"
  },
  "OpenAI": {
    "ChatModel": "o4-mini",
    "EmbeddingGeneratorModel": "text-embedding-3-small",
    "ImageModel": "dall-e-3",
    "AudioModel": "whisper-1",
    "VideoModel": ""
  },
  "AnthropicAI": {
    "ChatModel": "claude-haiku-4-5-20251001",
    "ImageModel": "",
    "AudioModel": "",
    "VideoModel": "",
    "EmbeddingGeneratorModel": "text-embedding-004" // Anthropic dosen't have its own embedding model, so we use Gemini/OpenAI/AzureAi models
  },
  "OllamaAI": {
    "ChatModel": "llama3.2:1b",
    "EmbeddingGeneratorModel": "mxbai-embed-large:latest",
    "ServerUrl": "http://localhost:11434",
    "ImageModel": "",
    "AudioModel": "",
    "VideoModel": ""
  },
  "AzureAI": {
    "ChatModel": "o4-mini",
    "Endpoint": "",
    "ChatDeployment": "",
    "ImageModel": "",
    "AudioModel": "",
    "VideoModel": "",
    "EmbeddingGeneratorModel": "text-embedding-3-small" // Azure OpenAI uses same models as OpenAI. more info: https://github.com/MicrosoftCloudEssentials-LearningHub/Azure-Text-Embedding-Overview
  }
}
